{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias Variance Trade-off\n",
    "\n",
    "- It is the point where we are adding just noise by adding model complexity (flexibility).\n",
    "- The training error goes down as it has to, but the test error is starting to go up.\n",
    "- The model after the bias trade-off begins to overfit.\n",
    "- It helps you understand the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Imagine that the center of the target (Round Bull's Eye) is a model that perfectly predicts the correct values.\n",
    "- As we move away from the bulls-eye, our predictions get worse and worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A common temptation for beginners is to continually add complexity to a model until it fits the training set very well.\n",
    "- Doing this can cause a model to overfit to your training data and cause large errors on new data, such as the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
